{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d099e73-921f-47b7-97d6-5a7a5e284642",
   "metadata": {},
   "source": [
    "3. Сгенерировать последовательности, которые состоят из цифр (от 0 до 9) и задаются следующим образом:\n",
    "x - последовательность цифр\n",
    "y1 = x1 \n",
    "yi = xi + x1\n",
    "Если yi >= 10 то yi = yi - 10\n",
    "Научить модель рекуррентной нейронной сети предсказывать yi по xi Использовать: RNN, LSTM, GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9ce4cc-44d1-4fc4-8e28-bb4794035b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from itertools import permutations\n",
    "import random\n",
    "import time\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c09698c-d5d3-4db0-9b0e-7223a90a0d9e",
   "metadata": {},
   "source": [
    "Подготовка данных\n",
    "Функция для перестановки заданного списка\n",
    "Генерируем последовательность из цифр от 0-9. Пример:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f904d-51b4-414b-8e97-7d344b2e64b8",
   "metadata": {},
   "source": [
    "[1, 2, 3, 4, 6, 8, 0, 7, 9, 5]\n",
    "[1, 2, 3, 4, 6, 8, 0, 9, 5, 7]\n",
    "[1, 2, 3, 4, 6, 8, 0, 9, 7, 5]\n",
    "[1, 2, 3, 4, 6, 9, 5, 7, 8, 0]\n",
    "[1, 2, 3, 4, 6, 9, 5, 7, 0, 8]\n",
    "[1, 2, 3, 4, 6, 9, 5, 8, 7, 0]\n",
    "[1, 2, 3, 4, 6, 9, 5, 8, 0, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "956e94ea-1044-40d9-b956-fed49c77a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# р закоментировано, так как размер файла становится слишком больши\n",
    "def permutation(lst):\n",
    " \n",
    "    # Если lst пуст, то перестановок нет\n",
    "    if len(lst) == 0:\n",
    "        return []\n",
    " \n",
    "    # если 1 элемент, то одна перестановка возможна\n",
    "   \n",
    "    if len(lst) == 1:\n",
    "        return [lst]\n",
    " \n",
    "    # Найдите перестановки для lst, если они существую\n",
    "    # более чем 1 символ\n",
    " \n",
    "    l = [] # пустой список, в котором будет храниться текущая перестановка\n",
    " \n",
    "    # Повторите ввод (lst) и вычислите перестановку\n",
    "    for i in range(len(lst)):\n",
    "       m = lst[i]\n",
    " \n",
    "       # Extract lst[i] or m from the list.  remLst is\n",
    "       # remaining list\n",
    "       remLst = lst[:i] + lst[i+1:]\n",
    " \n",
    "       # Генерация всех перестановок, где m является первым элементом\n",
    "       \n",
    "       for p in permutation(remLst):\n",
    "           l.append([m] + p)\n",
    "    return l\n",
    " \n",
    " \n",
    "# тест функции, добавим все перестановки в список\n",
    "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 0]\n",
    "list = []\n",
    "for p in permutation(data):\n",
    "    list.append(p)\n",
    "    #print (p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ec4e8a-446c-4fba-ad9d-c7a482e05ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 0],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8, 0, 9],\n",
       " [1, 2, 3, 4, 5, 6, 7, 9, 8, 0],\n",
       " [1, 2, 3, 4, 5, 6, 7, 9, 0, 8],\n",
       " [1, 2, 3, 4, 5, 6, 7, 0, 8, 9]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6af06eb6-0f90-4278-a2f8-e2b741fb20ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3628800"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#длина полученного списка\n",
    "len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fabe7e5-b4de-4063-9a80-d2b21e3bc5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#отбираем из списка по индексу кратный 50, так как list слишком большой\n",
    "Xdata = []\n",
    "for m in range(0, len(list)):\n",
    "    if m %50==0:\n",
    "        Xdata.append(list[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cc01b6e-5638-4c71-940f-e3c37ca05c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72576"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe9f60a0-023c-4a47-83df-57fb427d16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция - прописываем условия для Y\n",
    "def create_dataset(df):\n",
    "    set = []\n",
    "    ydata = []\n",
    "    set.append(df[0])\n",
    "    for i in range(1, len(df)):\n",
    "        set.append(df[i]+df[0])\n",
    "    for j in range(0, len(set)):\n",
    "        if set[j] >= 10:\n",
    "            ydata.append(set[j]-10)\n",
    "        else:\n",
    "            ydata.append(set[j]) \n",
    "    return ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63d91563-2f97-44a3-bec3-572528a5d79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 5, 6, 7, 8, 9, 0, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#тест\n",
    "df = [1, 2, 3, 4, 5, 6, 7, 8, 9, 0]\n",
    "create_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77ec8bb4-83a3-409c-9c67-59feda15da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#применяем фугкцию для всех элементов списка\n",
    "Ydata=[]\n",
    "for k in Xdata:\n",
    "    Ydata.append(create_dataset(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19508c40-9702-482b-a99d-bed2f116a688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72576"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f713ab9-bf6f-473f-991e-cf26d19f628a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 4, 5, 6, 7, 8, 9, 0, 1],\n",
       " [1, 3, 4, 5, 6, 9, 7, 0, 8, 1],\n",
       " [1, 3, 4, 5, 6, 1, 7, 0, 8, 9],\n",
       " [1, 3, 4, 5, 7, 8, 9, 6, 0, 1],\n",
       " [1, 3, 4, 5, 7, 0, 8, 9, 6, 1]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ydata[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc8fe77-d3f8-4961-9b49-f0b86a232049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbb1994c-4898-4bbe-823e-f115fd6466d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# делим на train/test\n",
    "num_trn = int(0.75*len(Xdata))                \n",
    "X_trn, Y_trn = Xdata[:num_trn], Ydata[:num_trn]\n",
    "X_test, Y_test = Xdata[num_trn:], Ydata[num_trn:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ddbc6ee-b8bd-4bcb-9a79-55cee92a1c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54432"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cd1b7b4-d6c4-433d-90d5-79519bd315f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54432"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa4eecbd-5e87-4898-9a21-16757444fbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18144"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "addb0e2e-4a71-43b4-8b4f-72864578ccc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18144"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04770f2d-5f53-4b69-90c6-6a3de3e68a1d",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df3223a7-9690-4d00-b55b-6301731effd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        # скрытое состояние\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # число скрытых слоев\n",
    "        self.layer_dim = layer_dim\n",
    "        # LSTM\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True) # batch_first=True (batch_dim, seq_dim, feature_dim)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # инициализация скрытого состояни, 0\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        # инициализация состояни ячейки памяти, 0\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        # Index hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "    \n",
    "input_dim = 10\n",
    "hidden_dim = 100\n",
    "layer_dim = 10\n",
    "output_dim = 10\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bd48f09-e5e1-4361-b67b-46f065755e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_dim=10, hidden_dim=100, layer_dim=1, output_dim=1)\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab4920f-02aa-4e74-a8dc-0e06995e749e",
   "metadata": {},
   "source": [
    "Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64e7e5ac-5d99-4424-bcb1-3490313f625f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([54432, 10])) that is different to the input size (torch.Size([54432, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 28.6768 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7416\\2169003629.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_trn = torch.tensor(X_trn, dtype = torch.float32).view(len(X_trn), 1, -1)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7416\\2169003629.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_trn = torch.tensor(Y_trn, dtype = torch.float32).view(len(Y_trn), -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 24.0056 | Epoch: 2, loss: 19.7648 | Epoch: 3, loss: 15.9122 | Epoch: 4, loss: 12.6498 | Epoch: 5, loss: 10.1838 | Epoch: 6, loss: 8.6565 | Epoch: 7, loss: 8.0824 | Epoch: 8, loss: 8.2937 | Epoch: 9, loss: 8.9006 | Epoch: 10, loss: 9.4534 | Epoch: 11, loss: 9.7238 | Epoch: 12, loss: 9.6987 | Epoch: 13, loss: 9.4611 | Epoch: 14, loss: 9.1149 | Epoch: 15, loss: 8.7513 | Epoch: 16, loss: 8.4376 | Epoch: 17, loss: 8.2144 | Epoch: 18, loss: 8.0958 | Epoch: 19, loss: 8.0730 | Epoch: 20, loss: 8.1212 | Epoch: 21, loss: 8.2081 | Epoch: 22, loss: 8.3021 | Epoch: 23, loss: 8.3780 | Epoch: 24, loss: 8.4202 | Epoch: 25, loss: 8.4234 | Epoch: 26, loss: 8.3908 | Epoch: 27, loss: 8.3323 | Epoch: 28, loss: 8.2608 | Epoch: 29, loss: 8.1897 | Epoch: 30, loss: 8.1303 | Epoch: 31, loss: 8.0902 | Epoch: 32, loss: 8.0722 | Epoch: 33, loss: 8.0746 | Epoch: 34, loss: 8.0918 | Epoch: 35, loss: 8.1163 | Epoch: 36, loss: 8.1403 | Epoch: 37, loss: 8.1572 | Epoch: 38, loss: 8.1636 | Epoch: 39, loss: 8.1587 | Epoch: 40, loss: 8.1445 | Epoch: 41, loss: 8.1250 | Epoch: 42, loss: 8.1045 | Epoch: 43, loss: 8.0871 | Epoch: 44, loss: 8.0755 | Epoch: 45, loss: 8.0708 | Epoch: 46, loss: 8.0721 | Epoch: 47, loss: 8.0778 | Epoch: 48, loss: 8.0851 | Epoch: 49, loss: 8.0917 | "
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    train_loss, train_acc, iter_num = .0, .0, .0\n",
    "    start_epoch_time = time.time()\n",
    "    model.train()\n",
    "    X_trn = torch.tensor(X_trn, dtype = torch.float32).view(len(X_trn), 1, -1)\n",
    "    Y_trn = torch.tensor(Y_trn, dtype = torch.float32).view(len(Y_trn), -1)\n",
    "    #print(X_trn.shape)\n",
    "    #print(Y_trn.shape)\n",
    "    optimizer.zero_grad() \n",
    "    out = model.forward(X_trn) \n",
    "    #print(out.shape)\n",
    "    out = out.view(len(Y_trn), -1)\n",
    "    #print(out.shape)\n",
    "    #print(Y_trn.shape)\n",
    "    l = loss(out, Y_trn)\n",
    "    train_loss += l.item()\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, loss: {train_loss:.4f}\",end=\" | \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad8046-4bc5-4ac0-9460-fbb2b8f115f2",
   "metadata": {},
   "source": [
    "Проверка на тестовый данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3388079-5428-4dcd-9d92-536acb7e15fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18144, 1])\n",
      "Epoch: 0, loss: 8.7995 | torch.Size([18144, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([18144, 10])) that is different to the input size (torch.Size([18144, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7416\\1396939477.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test, dtype = torch.float32).view(len(X_test), 1, -1)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7416\\1396939477.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_test = torch.tensor(Y_test, dtype = torch.float32).view(len(Y_test), -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 8.7957 | torch.Size([18144, 1])\n",
      "Epoch: 2, loss: 8.7816 | torch.Size([18144, 1])\n",
      "Epoch: 3, loss: 8.7650 | torch.Size([18144, 1])\n",
      "Epoch: 4, loss: 8.7647 | torch.Size([18144, 1])\n",
      "Epoch: 5, loss: 8.8057 | torch.Size([18144, 1])\n",
      "Epoch: 6, loss: 8.9043 | torch.Size([18144, 1])\n",
      "Epoch: 7, loss: 9.0479 | torch.Size([18144, 1])\n",
      "Epoch: 8, loss: 9.1796 | torch.Size([18144, 1])\n",
      "Epoch: 9, loss: 9.2129 | torch.Size([18144, 1])\n",
      "Epoch: 10, loss: 9.1002 | torch.Size([18144, 1])\n",
      "Epoch: 11, loss: 8.9000 | torch.Size([18144, 1])\n",
      "Epoch: 12, loss: 8.7645 | torch.Size([18144, 1])\n",
      "Epoch: 13, loss: 8.8684 | torch.Size([18144, 1])\n",
      "Epoch: 14, loss: 9.3446 | torch.Size([18144, 1])\n",
      "Epoch: 15, loss: 10.2329 | torch.Size([18144, 1])\n",
      "Epoch: 16, loss: 11.4203 | torch.Size([18144, 1])\n",
      "Epoch: 17, loss: 12.5708 | torch.Size([18144, 1])\n",
      "Epoch: 18, loss: 13.1889 | torch.Size([18144, 1])\n",
      "Epoch: 19, loss: 12.9964 | torch.Size([18144, 1])\n",
      "Epoch: 20, loss: 12.1504 | torch.Size([18144, 1])\n",
      "Epoch: 21, loss: 11.0030 | torch.Size([18144, 1])\n",
      "Epoch: 22, loss: 9.8865 | torch.Size([18144, 1])\n",
      "Epoch: 23, loss: 9.0690 | torch.Size([18144, 1])\n",
      "Epoch: 24, loss: 8.7626 | torch.Size([18144, 1])\n",
      "Epoch: 25, loss: 9.1322 | torch.Size([18144, 1])\n",
      "Epoch: 26, loss: 10.2970 | torch.Size([18144, 1])\n",
      "Epoch: 27, loss: 12.3236 | torch.Size([18144, 1])\n",
      "Epoch: 28, loss: 15.2088 | torch.Size([18144, 1])\n",
      "Epoch: 29, loss: 18.8458 | torch.Size([18144, 1])\n",
      "Epoch: 30, loss: 22.9757 | torch.Size([18144, 1])\n",
      "Epoch: 31, loss: 27.1417 | torch.Size([18144, 1])\n",
      "Epoch: 32, loss: 30.6989 | torch.Size([18144, 1])\n",
      "Epoch: 33, loss: 32.9612 | torch.Size([18144, 1])\n",
      "Epoch: 34, loss: 33.4769 | torch.Size([18144, 1])\n",
      "Epoch: 35, loss: 32.2173 | torch.Size([18144, 1])\n",
      "Epoch: 36, loss: 29.4983 | torch.Size([18144, 1])\n",
      "Epoch: 37, loss: 25.7864 | torch.Size([18144, 1])\n",
      "Epoch: 38, loss: 21.5844 | torch.Size([18144, 1])\n",
      "Epoch: 39, loss: 17.3812 | torch.Size([18144, 1])\n",
      "Epoch: 40, loss: 13.6210 | torch.Size([18144, 1])\n",
      "Epoch: 41, loss: 10.7152 | torch.Size([18144, 1])\n",
      "Epoch: 42, loss: 9.0461 | torch.Size([18144, 1])\n",
      "Epoch: 43, loss: 8.8948 | torch.Size([18144, 1])\n",
      "Epoch: 44, loss: 10.3203 | torch.Size([18144, 1])\n",
      "Epoch: 45, loss: 13.0377 | torch.Size([18144, 1])\n",
      "Epoch: 46, loss: 16.2535 | torch.Size([18144, 1])\n",
      "Epoch: 47, loss: 19.1076 | torch.Size([18144, 1])\n",
      "Epoch: 48, loss: 21.4993 | torch.Size([18144, 1])\n",
      "Epoch: 49, loss: 23.8647 | "
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    test_loss = .0\n",
    "    start_epoch_time = time.time()\n",
    "    model.eval()\n",
    "    X_test = torch.tensor(X_test, dtype = torch.float32).view(len(X_test), 1, -1)\n",
    "    Y_test = torch.tensor(Y_test, dtype = torch.float32).view(len(Y_test), -1)\n",
    "    out = model.forward(X_test) \n",
    "    out = out.view(len(Y_test), -1)\n",
    "    print(out.shape)\n",
    "    l = loss(out, Y_test)\n",
    "    test_loss += l.item()\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, loss: {test_loss:.4f}\",end=\" | \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81667954-0434-4bae-93c2-a79d33438495",
   "metadata": {},
   "source": [
    "Результаты неудовлетворительные по всем моделям (RNN/LSTM/GRU). Возможно некорректные данные для обучения или ошибки в модели"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
